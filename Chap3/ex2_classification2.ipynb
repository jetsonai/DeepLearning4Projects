{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "데이터 다운로드"
      ],
      "metadata": {
        "id": "Z2oOB-dGN5O6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"bhavikjikadara/dog-and-cat-classification-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "WOPPO7TYztEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls /kaggle/input/dog-and-cat-classification-dataset"
      ],
      "metadata": {
        "id": "RVTHsxt20kXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuzYABnxy5Ix"
      },
      "source": [
        "# 패키지 임포트\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIbn4Uuy6oXJ"
      },
      "source": [
        "#pytorch 버전 확인\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MeVa_ytzFQe"
      },
      "source": [
        "# GPU 사용 체크\n",
        "is_cuda = False\n",
        "if torch.cuda.is_available():\n",
        "    is_cuda = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UdkQoaeQP1N"
      },
      "source": [
        "파이토치 데이터셋 클래스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2IywNREzG4_"
      },
      "source": [
        "class PyTorchCustomDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 dataset_dir=\"/kaggle/input/dog-and-cat-classification-dataset/PetImages/\",\n",
        "                 transform=None,\n",
        "                 max_images=700):\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.transform = transform\n",
        "        self.max_images = max_images\n",
        "\n",
        "        self.label_list = os.listdir(self.dataset_dir)\n",
        "        print(f\"label_list: {len(self.label_list)}\")\n",
        "        self.label_list.sort()\n",
        "\n",
        "        self.x_list = []\n",
        "        self.y_list = []\n",
        "\n",
        "        total_count = 0\n",
        "\n",
        "        for label_index, label_str in enumerate(self.label_list):\n",
        "            img_path = os.path.join(self.dataset_dir, label_str)\n",
        "            if not os.path.isdir(img_path):\n",
        "                continue\n",
        "\n",
        "            img_list = os.listdir(img_path)\n",
        "            print(f\"{label_index} raw image count: {len(img_list)}\")\n",
        "\n",
        "            for img in img_list:\n",
        "                if total_count >= self.max_images:\n",
        "                    break\n",
        "\n",
        "                img_full_path = os.path.join(img_path, img)\n",
        "                if not os.path.isfile(img_full_path):\n",
        "                    continue\n",
        "\n",
        "                # PetImages 데이터셋은 깨진 파일이 섞여있을 수 있어 verify로 걸러줌\n",
        "                try:\n",
        "                    with Image.open(img_full_path) as im:\n",
        "                        im.verify()\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "                self.x_list.append(img_full_path)\n",
        "                self.y_list.append(label_index)\n",
        "                total_count += 1\n",
        "\n",
        "            if total_count >= self.max_images:\n",
        "                break\n",
        "\n",
        "        print(f\"[Dataset Info] Loaded images: {len(self.x_list)} (max={self.max_images})\")\n",
        "        print(f\"[Dataset Info] Classes: {self.label_list}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.x_list[idx]\n",
        "        label = self.y_list[idx]\n",
        "\n",
        "        image = Image.open(image_path)\n",
        "        if image.mode != \"RGB\":\n",
        "            image = image.convert(\"RGB\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __save_label_map__(self, dst_text_path=\"label_map.txt\"):\n",
        "        with open(dst_text_path, \"w\") as f:\n",
        "            for label in self.label_list:\n",
        "                f.write(label + \"\\n\")\n",
        "\n",
        "    def __num_classes__(self):\n",
        "        return len(self.label_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset_dir = \"/kaggle/input/dog-and-cat-classification-dataset/PetImages/\"\n",
        "train_ratio = 0.8\n",
        "BATCH_SIZE = 32  # 필요 시 사용자가 바꾸면 됨"
      ],
      "metadata": {
        "id": "YsW2I2OX4a1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = PyTorchCustomDataset(dataset_dir=dataset_dir, transform=transform, max_images=2000)\n",
        "dataset.__save_label_map__()\n",
        "num_classes = dataset.__num_classes__()\n",
        "\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "print(f\"train_size: {train_size}, test_size: {test_size}\")\n"
      ],
      "metadata": {
        "id": "ERn_uI584iKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=4\n",
        ")"
      ],
      "metadata": {
        "id": "BHPAjMf64mag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbaH1tDdZik2"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8WF5tV1UKYj"
      },
      "source": [
        "# 네트워크 정의\n",
        "import torch\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MODEL(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.network = models.resnet18(pretrained=True)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout()\n",
        "            , nn.Linear(1000, num_classes)\n",
        "            , nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.network(x)\n",
        "        return self.classifier(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rJpYqg6RXWz"
      },
      "source": [
        "main 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6fpTUpk_TKf"
      },
      "source": [
        "# 훈련 메인 함수 정의\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "train_losses , train_accuracy = [],[]\n",
        "val_losses , val_accuracy = [],[]\n",
        "\n",
        "def trainmain():\n",
        "    USE_CUDA = torch.cuda.is_available()\n",
        "    DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "    img_width, img_height = 224, 224\n",
        "    EPOCHS     = 12\n",
        "\n",
        "    #모델 객체 생성, PyTorch_Classification_Model.pt 모델 파일명 지정\n",
        "    model = MODEL(num_classes).to(DEVICE)\n",
        "    model_str = \"PyTorch_Classification_Model\"\n",
        "    model_str += \".pt\"\n",
        "\n",
        "    #최적화 함수와 학습률 지정\n",
        "    #optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "    acc = 0.0\n",
        "\n",
        "    # 에포크 만큼 훈련, 검증\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        model.train()\n",
        "        tr_loss = 0.0\n",
        "        tr_correct = 0.0\n",
        "        for data, target in (train_loader):\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            tr_loss += F.nll_loss(output,target,reduction='sum').item()\n",
        "            pred = output.data.max(dim=1,keepdim=True)[1]\n",
        "            tr_correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "        tr_ep_loss = tr_loss/len(train_loader.dataset)\n",
        "        tr_ep_accuracy = 100. * tr_correct/len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        te_loss = 0\n",
        "        te_correct = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in (test_loader):\n",
        "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "                output = model(data)\n",
        "                loss = F.cross_entropy(output, target)\n",
        "                te_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "                pred = output.max(1, keepdim=True)[1]\n",
        "                te_correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        te_ep_loss = te_loss / len(test_loader.dataset)\n",
        "        te_ep_accuracy = 100. * te_correct / len(test_loader.dataset)\n",
        "        print('[{}] Train Loss: {:.4f}, Train Accuracy: {:.2f}% Test Loss: {:.4f}, Test Accuracy: {:.2f}%'.format(\n",
        "                epoch, tr_ep_loss, tr_ep_accuracy, te_ep_loss, te_ep_accuracy))\n",
        "\n",
        "        if acc < te_ep_accuracy:\n",
        "            acc = te_ep_accuracy\n",
        "            torch.save(model.state_dict(), model_str)\n",
        "            print(\"model saved!\")\n",
        "\n",
        "        train_losses.append(tr_ep_loss)\n",
        "        train_accuracy.append(tr_ep_accuracy)\n",
        "        val_losses.append(te_ep_loss)\n",
        "        val_accuracy.append(te_ep_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1GP1bNcB0Fv"
      },
      "source": [
        "# 훈련 메인 함수 호출\n",
        "trainmain()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqbeFRs0kQSn"
      },
      "source": [
        "# 훈련 데이터와 검증 데이터의 손실 그래프\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(1,len(train_losses)+1),train_losses,'bo',label = 'training loss')\n",
        "plt.plot(range(1,len(val_losses)+1),val_losses,'r',label = 'validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CjLOKvOkQzu"
      },
      "source": [
        "# 훈련 데이터와 검증 데이터의 정확도 그래프\n",
        "plt.plot(range(1,len(train_accuracy)+1),train_accuracy,'bo',label = 'train accuracy')\n",
        "plt.plot(range(1,len(val_accuracy)+1),val_accuracy,'r',label = 'val accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch_Classification_Model.pt 모델 파일 확인\n",
        "!ls"
      ],
      "metadata": {
        "id": "5hiGbzHVtGqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지 분류 모델 추론 테스트"
      ],
      "metadata": {
        "id": "LTuXqp9UtXx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 이미지 로딩\n",
        "import os\n",
        "#PATH = \"/content/cats_and_dogs_filtered/validation\"\n",
        "#validation_cats_dir = PATH + '/cats'  # directory with our validation cat pictures\n",
        "#validation_dogs_dir = PATH + '/dogs'  # directory with our validation dog pictures\n",
        "PATH = \"/kaggle/input/dog-and-cat-classification-dataset/PetImages/\"\n",
        "validation_cats_dir = PATH + '/Cat'  # directory with our validation cat pictures\n",
        "validation_dogs_dir = PATH + '/Dog'  # directory with our validation dog pictures\n",
        "\n",
        "list_of_test_cats_images = os.listdir(validation_cats_dir)\n",
        "list_of_test_dogs_images = os.listdir(validation_dogs_dir)\n",
        "for idx in range(len(list_of_test_cats_images)):\n",
        "    list_of_test_cats_images[idx] = validation_cats_dir + '/'+list_of_test_cats_images[idx]\n",
        "for idx in range(len(list_of_test_dogs_images)):\n",
        "    list_of_test_dogs_images[idx] = validation_dogs_dir + '/'+list_of_test_dogs_images[idx]\n",
        "list_of_test_images = list_of_test_cats_images + list_of_test_dogs_images"
      ],
      "metadata": {
        "id": "zcvxgsaRpeMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 로딩된 이미지 경로 프린트\n",
        "print(list_of_test_cats_images[10])\n",
        "print(list_of_test_images[501])"
      ],
      "metadata": {
        "id": "rpceHOW5pjxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 보여주는 함수, 이미지 추론 함수\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#라벨맵 로딩 함수\n",
        "def load_label_map(textFile):\n",
        "    return np.loadtxt(textFile, str, delimiter='\\t')\n",
        "\n",
        "#이미지 읽는 함수\n",
        "def cv_image_read(image_path):\n",
        "    print(image_path)\n",
        "    return cv2.imread(image_path)\n",
        "\n",
        "#이미지 보여주는 함수\n",
        "def show_image(cv_image):\n",
        "    rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure()\n",
        "    plt.imshow(rgb)\n",
        "    plt.show()\n",
        "\n",
        "#이미지를 분류 모델로 추론한 결과를 텍스트로 보여주는 함수\n",
        "def print_result(inference_result, class_map):\n",
        "    class_text = class_map[np.argmax(inference_result)]\n",
        "    print(inference_result)\n",
        "    print(class_text)\n",
        "\n",
        "#이미지를 분류 모델로 추론하는 함수\n",
        "def inference_image(opencv_image, transform_info, model, DEVICE):\n",
        "    image = Image.fromarray(opencv_image)\n",
        "    image_tensor = transform_info(image)\n",
        "    image_tensor = image_tensor.unsqueeze(0)\n",
        "    image_tensor = image_tensor.to(DEVICE)\n",
        "    result = model(image_tensor)\n",
        "    return result"
      ],
      "metadata": {
        "id": "SvmudWzbpqHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 보여주는 함수 실습\n",
        "show_image(cv_image_read(list_of_test_images[10]))\n",
        "show_image(cv_image_read(list_of_test_images[501]))"
      ],
      "metadata": {
        "id": "OI0tfLADpsHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 메인 함수\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "def testmain(image_path):\n",
        "    USE_CUDA = torch.cuda.is_available()\n",
        "    DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "\n",
        "    img_width, img_height = 224, 224\n",
        "    transform_info = transforms.Compose([\n",
        "                transforms.Resize(size=(img_width, img_height))\n",
        "                , transforms.ToTensor()\n",
        "                    ])\n",
        "    #라벨 파일 읽기\n",
        "    class_map = load_label_map('label_map.txt')\n",
        "    num_classes = len(class_map)\n",
        "\n",
        "    #지정된 모델 로딩\n",
        "    model = MODEL(num_classes).to(DEVICE)\n",
        "    model_str = \"PyTorch_Classification_Model\"\n",
        "    model_str += \".pt\"\n",
        "\n",
        "    model.load_state_dict(torch.load(model_str))\n",
        "    model.eval()\n",
        "\n",
        "    #image_path = list_of_test_images[501]\n",
        "    opencv_image = cv_image_read(image_path)\n",
        "    inference_result = inference_image(opencv_image, transform_info, model, DEVICE)\n",
        "    inference_result = inference_result.cpu().detach().numpy()\n",
        "    print_result(inference_result, class_map)\n",
        "    show_image(opencv_image)"
      ],
      "metadata": {
        "id": "0sOjVXujp2P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 이미지로 테스트 메인 함수 실행 1\n",
        "image_path = list_of_test_images[10]\n",
        "testmain(image_path)\n",
        "\n",
        "# 테스트 이미지로 테스트 메인 함수 실행 2\n",
        "image_path = list_of_test_images[501]\n",
        "testmain(image_path)"
      ],
      "metadata": {
        "id": "fZDAhRuVqI5S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}