{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JinFree/DeepLearning4Projects/blob/main/Chap7/Train_YOLOv7_with_Pascal_VOC_in_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_XL3IxXElOq"
      },
      "source": [
        "이 노트북은 Colab에서 YOLOv7-tiny 모델을 VOC dataset으로 훈련하는 예제입니다.\n",
        "\n",
        "PASCAL VOC Dataset을 다운로드 받은 후 압축을 풀어줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8_EMIUPEWHL"
      },
      "outputs": [],
      "source": [
        "!pip install gdown\n",
        "!gdown 1w_WBizEt2e_u6T9iY-hkwA-fIVsJktbB\n",
        "!tar -xf VOCtrainval_11-May-2012.tar\n",
        "!rm VOCtrainval_11-May-2012.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fm7at7SEyEj"
      },
      "source": [
        "실습하고 있는 데이터셋은 라벨링이 xml 파일 포맷으로 제공되며, 해당 포맷은 YOLOv7을 활용해 객체 인식 신경망을 훈련할 때 사용할 수 있는 파일 포맷이 아닙니다.\n",
        "\n",
        "convert2Yolo라고 하는 깃허브 저장소에서 Pascal VOC 데이터셋의 xml 파일 형태를 YOLOv7를 통한 훈련에 사용할 수 있도록 변환하는 기능을 제공합니다. 이를 활용해 xml 파일 포맷을 txt 파일 포맷으로 변환하겠습니다.\n",
        "\n",
        "이 과정에 앞서 다음과 같이 Pascal VOC 데이터셋의 클래스 리스트가 있는 파일을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4gpn9DoE3ty"
      },
      "outputs": [],
      "source": [
        "classes = [\"aeroplane\\n\", \"bicycle\\n\", \"bird\\n\", \"boat\\n\", \"bottle\\n\",\n",
        "           \"bus\\n\", \"car\\n\", \"cat\\n\", \"chair\\n\", \"cow\\n\", \"diningtable\\n\",\n",
        "           \"dog\\n\", \"horse\\n\", \"motorbike\\n\", \"person\\n\", \"pottedplant\\n\",\n",
        "           \"sheep\\n\", \"sofa\\n\", \"train\\n\", \"tvmonitor\"]\n",
        "with open(\"vocnames.txt\", 'w') as f:\n",
        "    f.writelines(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT_RoSTYE5d7"
      },
      "source": [
        "vocnames.txt 파일이 생성된 것을 확인한 후 다음과 같이 VOCdevkit/VOC2012 폴더 아래에 labels 폴더를 생성한 후 convert2Yolo 저장소를 활용해 xml 파일을 txt 파일로 변환합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K728XjQE7MW"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ssaru/convert2Yolo.git\n",
        "!cd convert2Yolo && python3 example.py --datasets VOC \\\n",
        "--img_path ../VOCdevkit/VOC2012/JPEGImages/ \\\n",
        "--label ../VOCdevkit/VOC2012/Annotations/ \\\n",
        "--convert_output_path ../VOCdevkit/VOC2012/JPEGImages/ \\\n",
        "--img_type \".jpg\" \\\n",
        "--manifest_path ../ \\\n",
        "--cls_list_file ../vocnames.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJueJDgXE3En"
      },
      "source": [
        "다운로드 완료 후 훈련을 위한 이미지가 있는 폴더의 경로는 아래와 같습니다.\n",
        "\n",
        "/content/VOCdevkit/VOC2012/JPEGImages/\n",
        "\n",
        "YOLOv7를 통한 객체 인식 신경망을 훈련하기 위해 각 이미지 내 객체의 위치가 라벨링되어 있는 텍스트 파일은 이미지와 같은 폴더에 있습니다.\n",
        "\n",
        "YOLOv7에서 훈련할 때 이미지와 같은 경로에 이미지와 동일한 이름의 라벨링 된 텍스트 파일이 있어야만 훈련을 수행할 수 있습니다. 구체적인 파일 구조는 아래와 같습니다.\n",
        "\n",
        "\n",
        "```\n",
        "$Object_Detection_Dataset/\n",
        "                         ┗ 1.png\n",
        "                         ┗ 1.txt\n",
        "                         ┗ 2.jpg\n",
        "                         ┗ 2.txt\n",
        "\n",
        "```\n",
        "\n",
        "이제 데이터를 훈련 데이터와 검증 데이터로 나누겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJ8lm7kjFF1F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "data_root = \"/content/VOCData\"\n",
        "val_root = os.path.join(data_root, \"val\")\n",
        "train_root = os.path.join(data_root, \"train\")\n",
        "os.makedirs(val_root, exist_ok=True)\n",
        "os.makedirs(train_root, exist_ok=True)\n",
        "\n",
        "with open(\"/content/manifest.txt\") as f:\n",
        "    files = f.readlines()\n",
        "\n",
        "for idx, img_path in tqdm(enumerate(files)):\n",
        "    img_src = img_path.split('\\n')[0]\n",
        "    txt_src = os.path.splitext(img_src)[0] + \".txt\"\n",
        "    img_name = os.path.split(img_src)[-1]\n",
        "    text_name = os.path.split(txt_src)[-1]\n",
        "    if idx % 10 < 3:\n",
        "        img_dst = os.path.join(val_root, img_name)\n",
        "        text_dst = os.path.join(val_root, text_name)\n",
        "    else:\n",
        "        img_dst = os.path.join(train_root, img_name)\n",
        "        text_dst = os.path.join(train_root, text_name)\n",
        "    shutil.copy2(img_src, img_dst)\n",
        "    shutil.copy2(txt_src, text_dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSrs6vBlFFH7"
      },
      "source": [
        "이제 YOLOv7-tiny를 VOC dataset으로 훈련하도록 하겠습니다.\n",
        "\n",
        "학습을 위해 YOLOv7 환경을 구성하도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL9AWjOpFNKV"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/jetsonai/yolov7\n",
        "%cd yolov7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89axlIiVFcBX"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 코드로 형식 지정됨\n",
        "```\n",
        "\n",
        "훈련에 앞서 YOLOv5로 추론을 할 수 있는 환경인지 테스트해봅니다.\n",
        "\n",
        "검출은 아래와 같은 방식으로 할 수 있습니다.\n",
        "```\n",
        "python detect.py --source 0  # webcam\n",
        "                          img.jpg  # image\n",
        "                          vid.mp4  # video\n",
        "                          screen  # screenshot\n",
        "                          path/  # directory\n",
        "                         'path/*.jpg'  # glob\n",
        "                         'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
        "                         'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
        "```\n",
        "\n",
        "아래의 스크립트가 에러 없이 수행된다면 훈련할 준비가 되었습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqjfmDw0Fut-"
      },
      "outputs": [],
      "source": [
        "!python detect.py --weights yolov7-tiny.pt --img 640 --conf 0.25 --source inference/images\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(cv2.imread('runs/detect/exp/zidane.jpg'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j_oRua2HEr0"
      },
      "source": [
        "이제 훈련을 위한 설정 파일을 준비합니다.\n",
        "내용은 아래와 같습니다.\n",
        "\n",
        "YOLOv7는 darknet을 사용하는 이전의 YOLOv4와는 다르게 데이터셋이 있는 폴더 경로를 입력하여서 훈련에 사용할 수 있습니다.\n",
        "\n",
        "```\n",
        "train:  /content/VOCData/train\n",
        "val:  /content/VOCData/val\n",
        "\n",
        "# number of classes\n",
        "nc: 20\n",
        "\n",
        "# class names\n",
        "names: [ 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
        "         'bus', 'car', 'cat', 'chair', 'cow', 'diningtable',\n",
        "         'dog', 'horse', 'motorbike', 'person', 'pottedplant',\n",
        "         'sheep', 'sofa', 'train', 'tvmonitor' ]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drAa_pHBGDp0"
      },
      "outputs": [],
      "source": [
        "text_lines = '''\n",
        "train:  /content/VOCData/train\n",
        "val:  /content/VOCData/val\n",
        "\n",
        "# number of classes\n",
        "nc: 20\n",
        "\n",
        "# class names\n",
        "names: [ 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
        "         'bus', 'car', 'cat', 'chair', 'cow', 'diningtable',\n",
        "         'dog', 'horse', 'motorbike', 'person', 'pottedplant',\n",
        "         'sheep', 'sofa', 'train', 'tvmonitor' ]\n",
        "'''\n",
        "with open(\"/content/yolov7/vocdata.yaml\", 'w') as f:\n",
        "    f.write(text_lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZYJQqnoIAZr"
      },
      "source": [
        "이제 훈련을 수행하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLON1vQ0H6Mk"
      },
      "outputs": [],
      "source": [
        "!python train.py --img 320 --batch 8 --epochs 20 --data vocdata.yaml --weights yolov7-tiny.pt --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oMyqWPQIMMl"
      },
      "source": [
        "훈련이 완료되면 weight 파일을 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMLAmFvSIGcH"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/yolov7/runs/train/exp/weights/best.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKoXTClae_bs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPiLPPYoPYbIxE/5e9tF2v8",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
