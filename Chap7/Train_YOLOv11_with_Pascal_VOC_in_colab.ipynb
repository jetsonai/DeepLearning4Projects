{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "이 노트북은 Colab에서 YOLOv11n 모델을 VOC dataset으로 훈련하는 예제입니다.\n",
        "\n",
        "PASCAL VOC Dataset을 다운로드 받은 후 압축을 풀어줍니다."
      ],
      "metadata": {
        "id": "LzFrHUN2op3_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS31ZvkmXc_P"
      },
      "outputs": [],
      "source": [
        "!pip install gdown\n",
        "!gdown 1w_WBizEt2e_u6T9iY-hkwA-fIVsJktbB\n",
        "!tar -xf VOCtrainval_11-May-2012.tar\n",
        "!rm VOCtrainval_11-May-2012.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실습하고 있는 데이터셋은 라벨링이 xml 파일 포맷으로 제공되며, 해당 포맷은 YOLOv7을 활용해 객체 인식 신경망을 훈련할 때 사용할 수 있는 파일 포맷이 아닙니다.\n",
        "\n",
        "convert2Yolo라고 하는 깃허브 저장소에서 Pascal VOC 데이터셋의 xml 파일 형태를 YOLOv11을 통한 훈련에 사용할 수 있도록 변환하는 기능을 제공합니다. 이를 활용해 xml 파일 포맷을 txt 파일 포맷으로 변환하겠습니다.\n",
        "\n",
        "이 과정에 앞서 다음과 같이 Pascal VOC 데이터셋의 클래스 리스트가 있는 파일을 생성합니다."
      ],
      "metadata": {
        "id": "v9u2SAGuos4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"aeroplane\\n\", \"bicycle\\n\", \"bird\\n\", \"boat\\n\", \"bottle\\n\",\n",
        "           \"bus\\n\", \"car\\n\", \"cat\\n\", \"chair\\n\", \"cow\\n\", \"diningtable\\n\",\n",
        "           \"dog\\n\", \"horse\\n\", \"motorbike\\n\", \"person\\n\", \"pottedplant\\n\",\n",
        "           \"sheep\\n\", \"sofa\\n\", \"train\\n\", \"tvmonitor\"]\n",
        "with open(\"vocnames.txt\", 'w') as f:\n",
        "    f.writelines(classes)"
      ],
      "metadata": {
        "id": "4u9euDgWbUhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vocnames.txt 파일이 생성된 것을 확인한 후 다음과 같이 VOCdevkit/VOC2012 폴더 아래에 labels 폴더를 생성한 후 convert2Yolo 저장소를 활용해 xml 파일을 txt 파일로 변환합니다"
      ],
      "metadata": {
        "id": "zG3ysJB6oxu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ssaru/convert2Yolo.git\n",
        "!cd convert2Yolo && python3 example.py --datasets VOC \\\n",
        "--img_path ../VOCdevkit/VOC2012/JPEGImages/ \\\n",
        "--label ../VOCdevkit/VOC2012/Annotations/ \\\n",
        "--convert_output_path ../VOCdevkit/VOC2012/JPEGImages/ \\\n",
        "--img_type \".jpg\" \\\n",
        "--manifest_path ../ \\\n",
        "--cls_list_file ../vocnames.txt"
      ],
      "metadata": {
        "id": "qUBW6T9DbWA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다운로드 완료 후 훈련을 위한 이미지가 있는 폴더의 경로는 아래와 같습니다.\n",
        "\n",
        "/content/VOCdevkit/VOC2012/JPEGImages/\n",
        "\n",
        "YOLOv11을 통한 객체 인식 신경망을 훈련하기 위해 각 이미지 내 객체의 위치가 라벨링되어 있는 텍스트 파일은 이미지와 같은 폴더에 있습니다.\n",
        "\n",
        "YOLOv11에서 훈련할 때 이미지와 같은 경로에 이미지와 동일한 이름의 라벨링 된 텍스트 파일이 있어야만 훈련을 수행할 수 있습니다. 구체적인 파일 구조는 아래와 같습니다.\n",
        "\n",
        "\n",
        "```\n",
        "$Object_Detection_Dataset/\n",
        "                         ┗ 1.png\n",
        "                         ┗ 1.txt\n",
        "                         ┗ 2.jpg\n",
        "                         ┗ 2.txt\n",
        "\n",
        "```\n",
        "\n",
        "이제 데이터를 훈련 데이터와 검증 데이터로 나누겠습니다."
      ],
      "metadata": {
        "id": "ID33mSQqoz04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "data_root = \"/content/VOCData\"\n",
        "val_root = os.path.join(data_root, \"val\")\n",
        "train_root = os.path.join(data_root, \"train\")\n",
        "os.makedirs(val_root, exist_ok=True)\n",
        "os.makedirs(train_root, exist_ok=True)\n",
        "\n",
        "with open(\"/content/manifest.txt\") as f:\n",
        "    files = f.readlines()\n",
        "\n",
        "for idx, img_path in tqdm(enumerate(files)):\n",
        "    img_src = img_path.split('\\n')[0]\n",
        "    txt_src = os.path.splitext(img_src)[0] + \".txt\"\n",
        "    img_name = os.path.split(img_src)[-1]\n",
        "    text_name = os.path.split(txt_src)[-1]\n",
        "    if idx % 10 < 3:\n",
        "        img_dst = os.path.join(val_root, img_name)\n",
        "        text_dst = os.path.join(val_root, text_name)\n",
        "    else:\n",
        "        img_dst = os.path.join(train_root, img_name)\n",
        "        text_dst = os.path.join(train_root, text_name)\n",
        "    shutil.copy2(img_src, img_dst)\n",
        "    shutil.copy2(txt_src, text_dst)"
      ],
      "metadata": {
        "id": "ZxfLfX8MbXfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 YOLOv11n을 VOC dataset으로 훈련하도록 하겠습니다.\n",
        "\n",
        "학습을 위해 Ultralytics 패키지를 설치하도록 하겠습니다."
      ],
      "metadata": {
        "id": "ixtSEHGCo5Wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "LdWy07pqbYrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련에 앞서 YOLOv11n으로 추론을 할 수 있는 환경인지 테스트해봅니다.\n",
        "\n",
        "검출은 아래와 같은 방식으로 할 수 있습니다.\n",
        "```\n",
        "yolo predict model=yolo11n.pt --source 0  # webcam\n",
        "                                       img.jpg  # image\n",
        "                                       vid.mp4  # video\n",
        "                                       screen  # screenshot\n",
        "                                       path/  # directory\n",
        "                                       'path/*.jpg'  # glob\n",
        "                                       'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
        "                                       'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
        "```\n",
        "\n",
        "아래의 스크립트가 에러 없이 수행된다면 훈련할 준비가 되었습니다."
      ],
      "metadata": {
        "id": "Ohg8VONGpCak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/zidane.jpg'\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(cv2.imread('runs/detect/predict/zidane.jpg'))"
      ],
      "metadata": {
        "id": "XPRLBhAfbc2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 훈련을 위한 설정 파일을 준비합니다.\n",
        "내용은 아래와 같습니다.\n",
        "\n",
        "ultralytics에서는 훈련 DB를 아래와 같이 폴더 경로를 입력하여 설정할 수 있습니다.\n",
        "\n",
        "```\n",
        "path: /content/VOCData # dataset root dir\n",
        "train: train # train images (relative to 'path')\n",
        "val: val # val images (relative to 'path')\n",
        "test: #optional\n",
        "\n",
        "names:\n",
        "  0: aeroplane\n",
        "  1: bicycle\n",
        "  2: bird\n",
        "  3: boat\n",
        "  4: bottle\n",
        "  5: bus\n",
        "  6: car\n",
        "  7: cat\n",
        "  8: chair\n",
        "  9: cow\n",
        "  10: diningtable\n",
        "  11: dog\n",
        "  12: horse\n",
        "  13: motorbike\n",
        "  14: person\n",
        "  15: pottedplant\n",
        "  16: sheep\n",
        "  17: sofa\n",
        "  18: train\n",
        "  19: tvmonitor\n",
        "```\n"
      ],
      "metadata": {
        "id": "6nmfxYYopWFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_lines = \"\"\"path: /content/VOCData # dataset root dir\n",
        "train: train # train images (relative to 'path')\n",
        "val: val # val images (relative to 'path')\n",
        "test: #optional\n",
        "\n",
        "names:\n",
        "  0: aeroplane\n",
        "  1: bicycle\n",
        "  2: bird\n",
        "  3: boat\n",
        "  4: bottle\n",
        "  5: bus\n",
        "  6: car\n",
        "  7: cat\n",
        "  8: chair\n",
        "  9: cow\n",
        "  10: diningtable\n",
        "  11: dog\n",
        "  12: horse\n",
        "  13: motorbike\n",
        "  14: person\n",
        "  15: pottedplant\n",
        "  16: sheep\n",
        "  17: sofa\n",
        "  18: train\n",
        "  19: tvmonitor\"\"\"\n",
        "with open(\"/content/vocdata.yaml\", 'w') as f:\n",
        "    f.write(text_lines)"
      ],
      "metadata": {
        "id": "4R6xZ_dtcEq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 훈련을 수행하겠습니다."
      ],
      "metadata": {
        "id": "WHuoq2oopkmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# Train the model\n",
        "train_results = model.train(\n",
        "    data=\"vocdata.yaml\",  # path to dataset YAML\n",
        "    epochs=10,  # number of training epochs\n",
        "    imgsz=640,  # training image size\n",
        "    device=0,  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu\n",
        "    batch=64,\n",
        "    name=\"yolov11n_voc\",  # name of trained model\n",
        "    save_dir=\"runs/detect/yolov11n_voc\"\n",
        ")"
      ],
      "metadata": {
        "id": "w7t-nmWMdVK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련이 완료되면 평가 결과를 확인하고, 훈련 결과를 onnx로 변환합니다."
      ],
      "metadata": {
        "id": "iuU1sdKDpmT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val()\n",
        "model.export(format=\"onnx\")"
      ],
      "metadata": {
        "id": "2ZETPJy6mf6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "weight 파일과 onnx 파일을 다운로드합니다."
      ],
      "metadata": {
        "id": "bUz0szuIpsPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('runs/detect/yolov11n_voc/weights/best.pt')\n",
        "files.download('runs/detect/yolov11n_voc/weights/best.onnx')"
      ],
      "metadata": {
        "id": "_byPN6X9ltE5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}